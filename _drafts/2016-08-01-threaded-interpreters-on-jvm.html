---
layout: post
title: Threaded Interpreters on JVM?
date: '2016-08-01T11:47:00.000-07:00'
author: headius
tags: 
modified_time: '2016-08-01T11:47:59.047-07:00'
blogger_id: tag:blogger.com,1999:blog-4704664917418794835.post-1044095477250532431
blogger_orig_url: http://blog.headius.com/2016/08/threaded-interpreters-on-jvm.html
---

<div dir="ltr" style="text-align: left;" trbidi="on"><span style="background-color: white; color: #222222; font-family: arial, sans-serif; font-size: x-small;">Hello all!</span><br /><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">I'm at JVMLS, and as ideas come up I'm going to just post them here to get discussion going and so I don't lose them.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">For some time we (JRuby) have been working on our new IR, a register-based intermediate format we both interpret and use for JIT compilation to JVM bytecode.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">We have an interpreter for reasons many JVM language authors will understand: startup time *sucks* if you have to go all the way to bytecode before you start executing. Making matters worse, if you go all the way to bytecode, you *still* have to wait for the JVM to interpret that bytecode for a while before it will run fast.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">(The other reason we have an interpreter is to validate that our IR works properly before going to bytecode.)</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">Currently we have a mix of switch-based interpretation and polymorphic dispatch.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">Switch-based means we have an enum value Operation aggregated by our Instr class, and a switch branches. We have a primary larger switch for the most critical operations like variable set/get, branching, etc, and some of those cases call out to smaller switches for invocation type, runtime state manipulation, etc.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">There problems with this approach:</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">* Hotspot is currently pretty bad at optimizing switches. The main reason we split our switches into a couple levels is because the performance of large switches degrades quickly. And even when it does optimize, we're still branching all over the place, unpredictably.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">* Polymorphic dispatch has obvious problems. We have tried to reduce the complexity of the interpreter by making more Instr logic polymorphic, and performance drops off a cliff.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">Ok, but why is it important that we optimize our interpreter, if we're planning to eventually JIT anyway?</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">First off, Hotspot does not optimize large methods well. Ruby is a very terse language, and seemingly simple code can create gigantic amounts of JVM bytecode...frequently too much to even fit in a class, but also often too large for Hotspot to optimize well (or it will take a very long time to get there).</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">Second, in order to improve startup we often disable our JIT and reduce the JVM JIT to its simplest mode. The promises of "tiered compilation" have not really materialized for us...or at least they don't materialize during the critical first seconds of an application's startup. Our fastest-starting mode basically just goes straight into our simplest interpreter and starts running.</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">So, proceeding from the assumption that we need to have a faster interpreter, what are our options?</div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;"><br /></div><div style="color: #222222; font-family: arial, sans-serif; font-size: small;">Well the ideal is probably to eliminate the looping switch we have now. At the very least, it's problematic for the CPU to predict; we always branch to the same place, which then might branch to any of our instrs. It's similar to the issues dispatching via function objects at a polymorphic site.</div></div>