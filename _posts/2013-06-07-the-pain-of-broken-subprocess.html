---
layout: post
title: The Pain of Broken Subprocess Management on JDK
date: '2013-06-07T01:58:00.002-07:00'
author: headius
tags: 
modified_time: '2013-06-07T02:00:53.773-07:00'
blogger_id: tag:blogger.com,1999:blog-4704664917418794835.post-462657466694269626
blogger_orig_url: http://blog.headius.com/2013/06/the-pain-of-broken-subprocess.html
---

<script type="text/javascript">SyntaxHighlighter.defaults.gutter = false;</script><div dir="ltr" style="text-align: left;" trbidi="on">I prefer to write happy posts...I really do. But tonight I'm completely defeated by the JDK's implementation of subprocess launching, and I need to tell the world why.<br /><br />JRuby has always strived to mimic MRI's behavior as much as possible, which in many cases has meant we need to route around the JDK to get at true POSIX APIs and behaviors.<br /><br />For example, JRuby has provided the ability to manipulate symbolic links since well before Java 7 provided that capability, using a native POSIX subsystem built atop jnr-ffi, our Java-to-C FFI layer (courtesy of Wayne Meissner). Everyone in the Java world knew for years the lack of symlink support was a gross omission, but most folks just sucked it up and went about their business. We could not afford to do that.<br /><br />We've repeated this process for many other Ruby features: UNIX sockets, libc-like IO, selectable stdin, filesystem attributes...on and on. And we've been able to provide the best POSIX runtime on the JVM <b>bar none</b>. Nobody has gone as far or done as much as JRuby has.<br /><br />Another area where we've had to route around the JDK is in subprocess launching and management. The JDK provides java.lang.ProcessBuilder, an API for assembling the appropriate pieces of a subprocess launch, producing a java.lang.Process object. Process in turn provides methods to wait for the subprocess, get access to its streams, and destroy it forcibly. It works great, on the surface.<br /><br />Unfortunately, the cake is a lie.<br /><br />Under the covers, the JDK implements Process through a complicated series of tricks. We want to be able to interactively control the child process, monitor it for writes, govern its lifecycle exactly. The JDK attempts to provide a consistent experience across all platforms. Unfortunately, those two worlds are not currently compatible, and the resulting experience is consistently awful.<br /><br />We'll start at the bottom to see where things go wrong.<br /><br /><h4 style="text-align: left;">POSIX, POSIX, Everywhere</h4><br />At the core of ProcessBuilder, inside the native code behind UNIXProcess, we do find somewhat standard POSIX calls to fork and exec, wrapped up in a native downcall forkAndExec:<br /><br /><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[     /**      * Create a process using fork(2) and exec(2).      *      * @param std_fds array of file descriptors.  Indexes 0, 1, and      *        2 correspond to standard input, standard output and      *        standard error, respectively.  On input, a value of -1      *        means to create a pipe to connect child and parent      *        processes.  On output, a value which is not -1 is the      *        parent pipe fd corresponding to the pipe which has      *        been created.  An element of this array is -1 on input      *        if and only if it is <em>not</em> -1 on output.      * @return the pid of the subprocess      */     private native int forkAndExec(byte[] prog,                                    byte[] argBlock, int argc,                                    byte[] envBlock, int envc,                                    byte[] dir,                                    int[] std_fds,                                    boolean redirectErrorStream) ]]></script><br /></div>The C code behind this is a bit involved, so I'll summarize what it does.<br /><ol style="text-align: left;"><li>Sets up pipes for in, out, err, and fail to communicate with the eventual child process.</li><li>Copies the parent's descriptors from the pipes into the "fds" array.</li><li>Launches the child through a fairly standard fork+exec sequence.</li><li>Waits for the child to write a byte to the fail pipe indicating success or failure.</li><li>Scrubs the unused sides of the pipes in parent and child.</li><li>Returns the child process ID.</li></ol><div>This is all pretty standard for subprocess launching, and if it proceeded to put those file descriptors into direct, selectable channels we'd have no issues. Unfortunately, things immediately go awry once we return to the Java code.<br /><br /><h4 style="text-align: left;">Interactive?</h4><br />The call to forkAndExec occurs inside the UNIXProcess constructor, as the very first thing it does. At that point, it has in hand the three standard file descriptors and the subprocess pid, and it knows that the subprocess has at least been successfully forked. The next step is to wrap the file descriptors in appropriate InputStream and OutputStream objects, and this is where we find the first flaw.<br /><br /><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[             if (std_fds[0] == -1)                 stdin_stream = ProcessBuilder.NullOutputStream.INSTANCE;             else {                 FileDescriptor stdin_fd = new FileDescriptor();                 fdAccess.set(stdin_fd, std_fds[0]);                 stdin_stream = new BufferedOutputStream(                     new FileOutputStream(stdin_fd));             } ]]></script><br /></div>This is the code to set up an OutputStream for the input channel of the child process, so we can write to it. Now we know the operating system is going to funnel those written bytes directly to the subprocess's input stream, and ideally if we're launching a subprocess we intend to control it...perhaps by sending it interactive commands. Why, then, do we wrap the file descriptor with a BufferedOutputStream? <br />This is where JRuby's hacks begin. In our process subsystem, we have the following piece of code, which attempts to unwrap buffering from any stream it is given. <br /><br /><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[     /**      * Unwrap all filtering streams between the given stream and its actual      * unfiltered stream. This is primarily to unwrap streams that have      * buffers that would interfere with interactivity.      *      * @param filteredStream The stream to unwrap      * @return An unwrapped stream, presumably unbuffered      */     public static OutputStream unwrapBufferedStream(OutputStream filteredStream) {         if (RubyInstanceConfig.NO_UNWRAP_PROCESS_STREAMS) return filteredStream;         while (filteredStream instanceof FilterOutputStream) {             try {                 filteredStream = (OutputStream)                     FieldAccess.getProtectedFieldValue(FilterOutputStream.class,                         "out", filteredStream);             } catch (Exception e) {                 break; // break out if we've dug as deep as we can             }         }         return filteredStream;     } ]]></script></div><br />The FieldAccess.getProtectedFieldValue call there does what you think it does...attempt to read the "out" field from within FilteredOutputStream, which in this case will be the FileOutputStream from above. Unwrapping the stream in this way allows us to do two things:<br /><ol style="text-align: left;"><li>We can do unbuffered writes to (or reads from, in the case of the child's out and err streams) the child process.</li><li>We can get access to the more direct FileChannel for the stream, to do direct ByteBuffer reads and writes or low-level stream copying.</li></ol><div>So we're in good shape, right? It's a bit of hackery, but we've got our unbuffered Channel and can interact directly with the subprocess. Is this good enough?</div><div><br /></div><div>I wish it were.<br /><br /></div><h4 style="text-align: left;">Selectable?</h4><div><br />The second problem we run into is that users very often would like to select against the output streams of the child process, to perform nonblocking IO operations until the child has actually written some data. It gets reported as a JRuby bug over and over again because there's simply no way for us to implement it. Why? Because FileChannel is not selectable. <br /><br /><script class="brush: java;" type="syntaxhighlighter"><![CDATA[ public abstract class FileChannel     extends AbstractInterruptibleChannel     implements SeekableByteChannel, GatheringByteChannel, ScatteringByteChannel ]]></script><br />FileChannel implements methods for random-access reads and writes (positioning) and blocking IO interruption (which NIO implements by closing the stream...that's a rant for another day), but it does not implement any of the logic necessary for doing nonblocking IO using an NIO Selector. This comes up in at least one other place: the JVM's own standard IO streams are also not selectable, which means you can't select for user input at the console. Consistent experience indeed...it seems that all interaction with the user or with processes must be treated as file IO, with no selection capabilities. <br /><br />(It is interesting to note that the JVM's standard IO streams are *also* wrapped in buffers, which we dutifully unwrap to provide a truly interactive console.) <br /><br />Why are inter-proces file descriptors, which would support selector operations just wonderfully, wrapped in an unselectable channel? I have no idea, and it's impossible for us to hack around. <br /><br />Let's not dwell on this item, since there's more to cover. <br /><br /><h4 style="text-align: left;">Fear the Reaper</h4></div></div><div><br /></div><div>You may recall I also wanted to have direct control over the lifecycle of the subprocess, to be able to wait for it or kill it at my own discretion. And on the surface, Process appears to provide these capabilities via the waitFor() and destroy() methods. Again it's all smoke and mirrors.</div><div><br /></div><div>Further down in the UNIXProcess constructor, you'll find this curious piece of code:</div><div><br /></div><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[         /*          * For each subprocess forked a corresponding reaper thread          * is started.  That thread is the only thread which waits          * for the subprocess to terminate and it doesn't hold any          * locks while doing so.  This design allows waitFor() and          * exitStatus() to be safely executed in parallel (and they          * need no native code).          */          java.security.AccessController.doPrivileged(             new java.security.PrivilegedAction<void>() { public Void run() {                 Thread t = new Thread("process reaper") {                     public void run() {                         int res = waitForProcessExit(pid);                         synchronized (UNIXProcess.this) {                             hasExited = true;                             exitcode = res;                             UNIXProcess.this.notifyAll();                         }                     }                 };                 t.setDaemon(true);                 t.start();                 return null; }}); ]]></script> <div><br /></div><div>For each subprocess started through this API, the JVM will spin up a "process reaper" thread. This thread is designed to monitor the subprocess for liveness and notify the parent UNIXProcess object when that process has died, so it can pass on that information to the user via the waitFor() and exitValue() API calls.</div><div><br /></div><div>The interesting bit here is the waitForProcessExit(pid) call, which is another native downcall into C land:</div><div><br /><script class="brush: c;" type="syntaxhighlighter"><![CDATA[ /* Block until a child process exits and return its exit code.    Note, can only be called once for any given pid. */ JNIEXPORT jint JNICALL Java_java_lang_UNIXProcess_waitForProcessExit(JNIEnv* env,                                               jobject junk,                                               jint pid) {     /* We used to use waitid() on Solaris, waitpid() on Linux, but      * waitpid() is more standard, so use it on all POSIX platforms. */     int status;     /* Wait for the child process to exit.  This returns immediately if        the child has already exited. */     while (waitpid(pid, &status, 0) < 0) {         switch (errno) {         case ECHILD: return 0;         case EINTR: break;         default: return -1;         }     }      if (WIFEXITED(status)) {         /*          * The child exited normally; get its exit code.          */         return WEXITSTATUS(status);     } else if (WIFSIGNALED(status)) {         /* The child exited because of a signal.          * The best value to return is 0x80 + signal number,          * because that is what all Unix shells do, and because          * it allows callers to distinguish between process exit and          * process death by signal.          * Unfortunately, the historical behavior on Solaris is to return          * the signal number, and we preserve this for compatibility. */ #ifdef __solaris__         return WTERMSIG(status); #else         return 0x80 + WTERMSIG(status); #endif     } else {         /*          * Unknown exit code; pass it through.          */         return status;     } } ]]></script><br /><div><br /></div><div>There's nothing too peculiar here; this is how you'd wait for the child process to exit if you were writing plain old C code. But there's a sinister detail you can't see just by looking at this code: waitpid can be called <b>exactly once</b>&nbsp;by the parent process.</div><div><br /></div><div>Part of the Ruby Process API is the ability to get a subprocess PID and wait for it. The concept of a process ID has been around for a long time, and Rubyists (even amateur Rubyists who've never written a line of C code) don't seem to have any problem calling Process.waitpid when they want to wait for a child to exit. JRuby is an implementation of Ruby, and we would ideally like to be able to run all Ruby code that exists, so we also must implement Process.waitpid in some reasonable way. Our choice was to literally call the C function waitpid(2) via our FFI layer.</div><div><br /></div><div>Here's the subtle language from the wait(2) manpage (which includes waitpid):</div><div><pre><br />RETURN VALUES<br />     If wait() returns due to a stopped or terminated child<br />     process, the process ID of the child is returned to the<br />     calling process.  Otherwise, a value of -1 is returned<br />     and errno is set to indicate the error.<br /><br />     If wait3(), wait4(), or waitpid() returns due to a<br />     stopped or terminated child process, the process ID of<br />     the child is returned to the calling process.  If there<br />     are no children not previously awaited, -1 is returned<br />     with errno set to [ECHILD].  Otherwise, if WNOHANG is<br />     specified and there are no stopped or exited children,<br />     0 is returned. If an error is detected or a caught<br />     signal aborts the call, a value of -1 is returned and<br />     errno is set to indicate the error.<br /></pre></div><div>There's a lot of negatives and passives and conditions there, so I'll spell it out for you more directly: If you call waitpid for a given child PID and someone else in your process has already done so...bad things happen.</div><div><br /></div><div>We effectively have to race the JDK to the waitpid call. If we get there first, the reaper thread bails out immediately and does no further work. If we don't get their first, it becomes impossible for a Ruby user to waitpid for that child process.</div><div><br /></div><div>Now you may be saying "why don't you just wait on the Process object and let the JDK do its job, old man? The problem here is that Ruby's Process API behaves like a POSIX process API: you get a PID back, and you wait on that PID. We can't mimic that API without returning a PID and implementing Process.waitpid appropriately.</div><div><br /></div><div>(Interesting note: we also use reflection tricks to get the real PID out of the java.lang.Process object, since it is not normally exposed.)</div><div><br /></div><div>Could we have some internal lookup table mapping PIDs to Process objects, and make our wait logic just call Process.waitFor? In order to do so, we'd need to manage a weak-valued map from integers to Process objects...which is certainly doable, but it breaks if someone uses a native library or FFI call to launch a process themselves. Oh, but if it's not in our table we could do waitpid. And so the onion grows more layers, all because we can't simply launch a process, get a PID, and wait on it.</div><div><br /></div><div>It doesn't end here, though.</div><div><br /></div><h4 style="text-align: left;">Keep Boiling That Ocean</h4><div><br /></div><div>At this point we've managed to at least get interactive streams to the child process, and even if they're not selectable that's a big improvement over the standard API. We've managed to dig out a process ID and sometimes we can successfully wait for it with a normal waitpid function call. So out of our three goals (interactivity, selectability, lifecycle control) we're maybe close to halfway there.</div><div><br /></div><div>Then the JDK engineers go and pull the rug out from under us.</div><div><br /></div><div>The logic for UNIXProcess has changed over time. Here's the notable differences in the current JDK 7 codebase:</div><div><ul style="text-align: left;"><li>An Executor is now used to avoid spinning up a new thread for each child process. I'd&nbsp;+1 this, if the reaping logic weren't already causing me headaches.</li><li>The streams are now instances of UNIXProcess.ProcessPipeOutputStream and ProcessPipeInputStream. Don't get excited...they're still just buffered wrappers around File streams.</li><li>The logic run when the child process exist has changed...with catastrophic consequences.</li></ul><div>Here's the new stream setup and reaper logic:</div></div><div><br /><script class="brush: java;" type="syntaxhighlighter"><![CDATA[      void initStreams(int[] fds) throws IOException {         stdin = (fds[0] == -1) ?             ProcessBuilder.NullOutputStream.INSTANCE :             new ProcessPipeOutputStream(fds[0]);          stdout = (fds[1] == -1) ?             ProcessBuilder.NullInputStream.INSTANCE :             new ProcessPipeInputStream(fds[1]);          stderr = (fds[2] == -1) ?             ProcessBuilder.NullInputStream.INSTANCE :             new ProcessPipeInputStream(fds[2]);          processReaperExecutor.execute(new Runnable() {             public void run() {                 int exitcode = waitForProcessExit(pid);                 UNIXProcess.this.processExited(exitcode);             }});     } ]]></script></div><div><br /></div><div>Now instead of simply notifying the UNIXProcess that the child has died, there's a call to processExited().</div><div><br /></div><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[     void processExited(int exitcode) {         synchronized (this) {             this.exitcode = exitcode;             hasExited = true;             notifyAll();         }          if (stdout instanceof ProcessPipeInputStream)             ((ProcessPipeInputStream) stdout).processExited();          if (stderr instanceof ProcessPipeInputStream)             ((ProcessPipeInputStream) stderr).processExited();          if (stdin instanceof ProcessPipeOutputStream)             ((ProcessPipeOutputStream) stdin).processExited();     } ]]></script></div><div><br /></div><div>Ok, doesn't look bad so far. Let's look at ProcessPipeInputStream, which handles output from the child process.</div><div><br /></div><div><script class="brush: java;" type="syntaxhighlighter"><![CDATA[     /**      * A buffered input stream for a subprocess pipe file descriptor      * that allows the underlying file descriptor to be reclaimed when      * the process exits, via the processExited hook.      *      * This is tricky because we do not want the user-level InputStream to be      * closed until the user invokes close(), and we need to continue to be      * able to read any buffered data lingering in the OS pipe buffer.      */     static class ProcessPipeInputStream extends BufferedInputStream {         ProcessPipeInputStream(int fd) {             super(new FileInputStream(newFileDescriptor(fd)));         }          private static byte[] drainInputStream(InputStream in)                 throws IOException {             if (in == null) return null;             int n = 0;             int j;             byte[] a = null;             while ((j = in.available()) > 0) {                 a = (a == null) ? new byte[j] : Arrays.copyOf(a, n + j);                 n += in.read(a, n, j);             }             return (a == null || n == a.length) ? a : Arrays.copyOf(a, n);         }          /** Called by the process reaper thread when the process exits. */         synchronized void processExited() {             // Most BufferedInputStream methods are synchronized, but close()             // is not, and so we have to handle concurrent racing close().             try {                 InputStream in = this.in;                 if (in != null) {                     byte[] stragglers = drainInputStream(in);                     in.close();                     this.in = (stragglers == null) ?                         ProcessBuilder.NullInputStream.INSTANCE :                         new ByteArrayInputStream(stragglers);                     if (buf == null) // asynchronous close()?                         this.in = null;                 }             } catch (IOException ignored) {                 // probably an asynchronous close().             }         }     } ]]></script></div><div><br /></div><div>So when the child process exits, the any data waiting to be read from its output stream is drained into a buffer. <b>All of it. In memory.</b></div><div><br /></div><div>Did you launch a process that writes a gigabyte of data to its output stream and then terminates? Well, friend, I sure hope you have a gigabyte of memory, because the JDK is going to read that sucker in and there's nothing you can do about it. And let's hope there's not more than 2GB of data, since this code basically just grows a byte[], which in Java can only grow to 2GB. If there's more than 2GB of data on that stream, this logic errors out and the data is lost forever.  Oh, and by the way...if you happened to be devlishly clever and managed to dig down to the real FileChannel attached to the child process, all the data from that stream has suddenly disappeared, and the channel itself is closed, even if you never got a chance to read from it. Thanks for the help, JDK.</div><div><br /></div><div>The JDK has managed to both break our clever workarounds (for its previously broken logic) an break itself even more badly. It's almost like they want to make subprocess launching so dreadfully bad you just don't use it anymore.</div><div><br /></div><h4 style="text-align: left;">Never Surrender</h4><div><br /></div><div>Of course I could cry into my beer over this, but these sorts of problems and challenges are exactly why I'm involved in JRuby and OpenJDK. Obviously this API has gone off the deep end and can't be saved, so what's a hacker to do? In our case, we make our own API.</div><div><br /></div><div>At this point, that's our only option. The ProcessBuilder and Process APIs are so terribly broken that we can't rely on them anymore. Thankfully, JRuby ships with a solid, fast FFI layer called the Java Native Runtime (JNR) that should make it possible for us to write our own process API entirely in Java. We will of course do that in the open, and we are hoping you will help us.</div><div><br /></div><div>What's the moral of the story? I don't really know. Perhaps it's that lowest-common-denominator APIs usually trend toward uselessness. Perhaps it's that ignoring POSIX is an expressway to failure. Perhaps it's that I don't know when to quit. In any case, you can count on the JRuby team to continue bringing you the only true POSIX experience on the JVM, and you can count on me to keep pushing OpenJDK to follow our lead.</div></div></div></div>