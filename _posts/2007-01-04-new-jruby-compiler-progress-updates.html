---
layout: post
title: 'New JRuby Compiler: Progress Updates'
date: '2007-01-04T02:54:00.000-08:00'
author: headius
tags:
- compiler
- ruby
- jruby
modified_time: '2011-01-25T21:44:33.357-08:00'
blogger_id: tag:blogger.com,1999:blog-4704664917418794835.post-5250912085308783895
blogger_orig_url: http://blog.headius.com/2007/01/new-jruby-compiler-progress-updates.html
---

I've been cranking away on the new compiler. I'm a bit tired and planning to get some sleep, but I've gotten the following working:<br /><ul><li>all three kinds of calls</li><li>local variables</li><li>string, fixnum, array literals</li><li>'def' for simple methods and arg lists</li><li>closures</li></ul>Now that last item comes with a big caveat: I have no way to pass closures I create. The code is compiling, basically as a Closure class that you initialize with local variables and invoke. But since block management in JRuby is still heavily dependent on ThreadContext nonsense, there's no easy way to pass it to a given method. So the next step to getting closures to work in the compiler is to start passing them on the call path as a parameter, much like we do for ThreadContext.<br /><br />I've managed to keep the compiler fairly well isolated between node walking and bytecode generation, though the bytecode generator impl I have currently is getting a little large and cumbersome. It's commented to death, but it's pushing 900 LOC. It needs some heavy refactoring. However, it's behind a fairly straightforward interface, so the node-walking code doesn't ever see the ugliness. I believe it will be much easier to maintain, and it's certainly easier to follow.<br /><br />In general, things are moving along well. I'm skipping edge cases for some nodes at the moment to get bulk code compiling. There's a potential that as this fills out more and handles compiling more code, it could start to be wired in as a JIT. Since it can fail gracefully if it can't compile an AST, we'd just drop back to interpreted mode in those cases.<br /><br />So that's it.<br /><br />...<br /><br />Ok, ok, here's performance numbers. Twist my arm why don't you.<br /><br />(best times only)<br /><br />The new method dispatch benchmark tests 100M calls to a simple no-arg method that returns 'self', in this case Fixnum#to_i. The first part of the test is a control run that just does 100M local variable lookups.<br /><pre>method dispatch, control (var access only):<br /> interpreted, client VM: 1.433<br /> interpreted, server VM: 1.429<br /> ruby 1.8.5: 0.552<br /> compiled, client VM: 0.093<br /> compiled, server VM: 0.056</pre>Much better. The compiler handles local var lookups using an array, rather than going through ThreadContext to get a DynamicScope object. Much faster, and HotSpot hits it pretty hard. At worst it takes about 0.223s, so it's faster than Ruby even before HotSpot gets ahold of it. The second part of the test just adds in the method calls.<br /><pre>method dispatch, test (with method calls):<br /> interpreted, client VM: 5.109<br /> interpreted, server VM: 3.876<br /> ruby 1.8.5: 1.294<br /> compiled, client VM: 3.167<br /> compiled, server VM: 1.932</pre>Better than interpreted, but slow method lookup and dispatch is still getting in the way. Once we find a single fast way to dynamic dispatch I think this number will improve a lot.<br /><br />So then, on to the good old fib tests.<br /><pre>recursive fib:<br /> interpreted, client VM: 6.902<br /> interpreted, server VM: 5.426<br /> ruby 1.8.5: 1.696<br /> compiled, client VM: 3.721<br /> compiled, server VM: 2.463</pre>Looking a lot better, and showing more improvement over interpreted than the previous version of the compiler. It's not as fast as Ruby, but with the client VM it's under 2x and with the server VM it's in the 1.5x range. Our heavyweight Fixnum and method dispatch issues are to blame for the remaining performance trouble.<br /><pre>iterative fib:<br /> interpreted, client VM: 17.865<br /> interpreted, server VM: 13.284<br /> ruby 1.8.5: 17.317<br /> compiled, client VM: 17.549<br /> compiled, server VM: 12.215</pre>Finally the compiler shows some improvement over the interpreted version for this benchmark! Of course this one's been faster than Ruby in server mode for quite a while, and it's more a test of Java's BigInteger support than anything else, but it's a fun one to try.<br /><br />All the benchmarks are available in test/bench/compiler, and you can just run them directly. If you like, you can open them up and see how to use the compiler yourself; it's pretty easy. I will be continuing to work on this after I get some sleep, but any feedback is welcome.