---
layout: post
title: 'Another Performance Discovery: REXML'
date: '2007-10-17T17:07:00.000-07:00'
author: headius
tags: 
modified_time: '2011-01-25T21:44:32.459-08:00'
blogger_id: tag:blogger.com,1999:blog-4704664917418794835.post-3253599371210847247
blogger_orig_url: http://blog.headius.com/2007/10/another-performance-discovery-rexml.html
---

I've discovered a really awful bottleneck in REXML processing.<br /><br />Look at these results for parsing our build.xml:<br /><pre>read content from stream, no DOM<br />2.592000   0.000000   2.592000 (  2.592000)<br />1.326000   0.000000   1.326000 (  1.326000)<br />0.853000   0.000000   0.853000 (  0.853000)<br />0.620000   0.000000   0.620000 (  0.620000)<br />0.471000   0.000000   0.471000 (  0.471000)<br />read content once, no DOM<br />5.323000   0.000000   5.323000 (  5.323000)<br />5.328000   0.000000   5.328000 (  5.328000)<br />5.209000   0.000000   5.209000 (  5.209000)<br />5.173000   0.000000   5.173000 (  5.173000)<br />5.138000   0.000000   5.138000 (  5.138000)</pre><br />When reading from a stream, the content is read in in chunks, with each chunk being matched in turn. Because our current regexp engine uses char[] instead of byte[], each chunk must be decoded into UTF-16 characters, matched, and encoded back into UTF-8 bytes.<br /><br />For small chunks, like those read off a stream, this decode/encode cycle is fairly quick. Here, the streamed numbers are pretty close to MRI. However, when an XML string is parsed from memory, the process goes like this:<br /><ol><li>set buffer to entire string</li><li>match against the buffer</li><li>set buffer to post match (remainder of the string)</li></ol>Now this is obviously a little inefficient, since it creates a lot of extra strings, but a copy-on-write String implementation helps a lot. However in our case it also means that we decode/encode the entire remaining XML string for every element match. For any nontrivial file, this is *terrible* overhead.<br /><br />So what's the fix? Here's the same second benchmark using a StringIO object passed to the parser instead, with a simple change to rexml/source.rb:<br /><br />Diff:<br /><pre>Index: lib/ruby/1.8/rexml/source.rb<br />===================================================================<br />--- lib/ruby/1.8/rexml/source.rb        (revision 4596)<br />+++ lib/ruby/1.8/rexml/source.rb        (working copy)<br />@@ -1,4 +1,5 @@<br />require 'rexml/encoding'<br />+require 'stringio'<br /><br />module REXML<br />       # Generates Source-s.  USE THIS CLASS.<br />@@ -8,7 +9,7 @@<br />               # @return a Source, or nil if a bad argument was given<br />               def SourceFactory::create_from arg#, slurp=true<br />      if arg.kind_of? String<br />-                         Source.new(arg)<br />+                         IOSource.new(StringIO.new(arg))<br />      elsif arg.respond_to? :read and<br />            arg.respond_to? :readline and<br />            arg.respond_to? :nil? and</pre><br />New numbers:<br /><pre>read content once, no DOM<br />0.640000   0.000000   0.640000 (  0.640000)<br />0.693000   0.000000   0.693000 (  0.693000)<br />0.542000   0.000000   0.542000 (  0.542000)<br />0.349000   0.000000   0.349000 (  0.349000)<br />0.336000   0.000000   0.336000 (  0.336000)</pre><br />This is a perfect indication why JRuby's Rails performance is currently nowhere near what it will be. We continue to find these little gems...and there's no telling how many more are out there. With recent <a href="http://headius.blogspot.com/2007/10/performance-update.html">execution performance numbers</a> looking <a href="http://ola-bini.blogspot.com/2007/10/mystery-expos-on-jruby-performance.html">extremely solid</a> and recent Rails performance getting <a href="http://ola-bini.blogspot.com/2007/10/updated-jruby-on-rails-performance.html">closer and closer</a>, the upcoming 1.1 release ought to be amazing.